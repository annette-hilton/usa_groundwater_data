---
title: "USGS Data Import and Wrangling"
author: "Annette Hilton"
date: "11/30/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, error = FALSE, warning = FALSE)
```

## Introduction

This document is complimentary to "USA Well Water Data" (`usa_groundwater_metadata.Rmd`). Please reference "USA Well Water Data" for more information regarding the goals and parameters of the project.

Here USGS groundwater data is auto-downloaded from the internet (urls) and tidied.  

## Steps

1. Auto-download USGS groundwater well data from two different websites 
  a. USGS REST Services (https://waterservices.usgs.gov/rest/GW-Levels-Test-Tool.html)
  b. USGS Groundwater Levels for the Nation, Historical Observations (https://nwis.waterdata.usgs.gov/nwis/si) 
    **Note: this page is being depreciated Jan, 2023 
    
2. Read in files 
3. Create one large data set, tidy data
  
  
## Github/Rproject Set Up 

If you have forked and cloned this repo from Github, you must set up your workspace in the following way to ensure the code runs properly (or edit the code as you see fit). 

- **Folders/File paths** in your Rproject must match the code. Create folders: 
  - "urls": contains folders "usgs_rest" and "usgs_gwn" 
  - "usgs_rest" : empty folder that the R code will write the resulting data files into from USGS REST 
  - "usgs_gwn" : empty folder that the R code will write the resulting data files into from USGS Groundwater for the Nation 


```{r}
# Attach packages

library(tidyverse)
library(here)
library(lubridate)
library(glue)
library(curl)
library(readtext)
library(purrr)
library(janitor)
library(data.table)

# Disable scientific notation 

options(scipen=999)

```


### Step 1. Autodownload Data Files USGS 

Steps: 

1. Create list of state abbreviations for all states/territories to download 
2. Iteratively download files for all states/territories to folder "usgs_rest" for USGS REST data 
3. Iteratively download files for all states/terriroties to folder "usgs_gwn" for USGS Groundwater for the Nation 


1. State Abbreviations for both Data Downloads 

```{r}
# Make list of state (and territory) abbreviations 

states <- c("ak", "al", "ar", "az", "ca", "co", "ct", "dc", "de", "fl", "ga", "gu", "hi", "ia", "id", "il", "in", "ks", "ky", "la", "ma", "md", "me", "mi", "mn", "mo", "ms", "mt", "nc", "nd", "ne", "nh", "nj", "nm", "nv", "ny", "oh", "ok", "or", "pa", "pr", "ri", "sc", "sd", "tn", "tx", "ut", "va", "vi", "vt", "wa", "wi", "wv",  "wy")

```
  
2. USGS REST Services Data Download 

You must update this URL by date (most recent date, or date desired) 

```{r}
# Designate URL to search for (USGS REST Services), with {state} added to iterate through state abbreviations/different URLS 

# Change date from 2021-12-01 to desired modern date (start date set at 1800-01-01)
url_usgs_rest <- glue("https://waterservices.usgs.gov/nwis/gwlevels/?format=rdb&stateCd={states}&startDT=1800-01-01&endDT=2021-12-01&siteType=GW&siteStatus=all")

# Designate a place for downloaded files to live (create folder, and designate name for files once downloaded)

names_usgs_rest <- here::here("urls", "usgs_rest", glue("usgs_rest_{states}.tsv"))

# Use `walk2()` and `curl_download()` to iteratively download the files indicated 

walk2(url_usgs_rest, names_usgs_rest, curl_download, mode = "wb")

```
 
3. USGS Groundwater for the Nation Data Download 

URL should not need to be updated 

```{r}
# Designate URL to search for (USGS Groundwater for the Nation), with {state} added to iterate through state abbreviations/different URLS 

url_usgs_gwn <- glue("https://nwis.waterdata.usgs.gov/{states}/nwis/inventory?site_tp_cd=GW&group_key=NONE&format=sitefile_output&sitefile_output_format=rdb&column_name=agency_cd&column_name=site_no&column_name=station_nm&column_name=dec_lat_va&column_name=dec_long_va&column_name=state_cd&column_name=alt_va&column_name=well_depth_va&column_name=hole_depth_va&list_of_search_criteria=site_tp_cd")

# Designate a place for downloaded files to live (create folder, and designate name for files once downloaded)

names_usgs_gwn <- here::here("urls", "usgs_gwn", glue("usgs_gwn_{states}.tsv"))

# Use `walk2()` and `curl_download()` to iteratively download the files indicated 

walk2(url_usgs_gwn, names_usgs_gwn, curl_download, mode = "wb")
```

### Step 2. Read in Files 

**NOTE** Change file path to personal computer file path 

```{r}
# Read in USGS REST files just downloaded
# Use `read.table()` for reading in files, use `map_df()` to make it iterative 
# Specify `header = TRUE` to indicate first row should be column headers 
# Assign file name as column (`set_names()`) and (.id = source) and then remove everything except the state abbreviation
# **NOTE** You must change the file path to your own computer file path to remove 
  
usgs_rest_all <- 
  list.files(path = here::here("urls", "usgs_rest"), 
             pattern = "*.tsv", full.names = T) %>% 
  set_names() %>% 
  map_df(~read.table(., fill = TRUE, header = TRUE, sep = "\t", na.strings = c("NA", "")), .id = "source") %>% 
  filter(!agency_cd == "5s") %>% 
  mutate(id = str_remove(source, "C:/Users/aeliz/Dropbox/Documents/github/usa_groundwater_data/urls/usgs_rest/usgs_rest_"), # Change this file path
         id = str_remove(id, ".tsv")) %>% 
  select(-source)

# Read in USGS Groundwater for the Nation files just downloaded
# Use `fread()` for reading in files, use `map_df()` to make it iterative
# Specify `header = TRUE` to indicate first row should be column headers
# Assign file name as column (`set_names()`) and (.id = source) and then remove everything except the state abbreviation
# **NOTE** You must change the file path to your own computer file path to remove 

usgs_gwn_all <-
    list.files(path = here::here("urls", "usgs_gwn"),
               pattern = "*.tsv", full.names = T) %>% 
  set_names() %>% 
    map_df(~read.table(., fill = TRUE, header = TRUE, sep = "\t", quote = "", na.strings = c("NA", "")), .id = "source") %>% 
    filter(!agency_cd == "5s") %>% 
    mutate(id = str_remove(source, "C:/Users/aeliz/Dropbox/Documents/github/usa_groundwater_data/urls/usgs_gwn/usgs_gwn_"), # Change this file path 
         id = str_remove(id, ".tsv")) %>% 
    select(-source, -"X..DOCTYPE.html.")

```

### Step 3. Join files and tidy 

```{r}
# Use full join to merge both data sets (by site_no) 

full_join_usgs <- full_join(x = usgs_gwn_all, y = usgs_rest_all, by = "site_no") 

# Tidy dataframe: add dates (lubridate) 

entire_usa_2021 <- full_join_usgs %>% 
  mutate(
    level_date = lubridate::parse_date_time(lev_dt, orders = c("ymd", "Y!", "Ym"), train = FALSE), 
    level_decimal_date = lubridate::decimal_date(level_date),
    level_month = lubridate::month(level_date, label = TRUE),
    level_year = lubridate::year(level_date))
  
  
```

### Step 4. Write file to tsv 

```{r}
write_tsv(entire_usa_2021, "entire_usa_2021.txt")
```


