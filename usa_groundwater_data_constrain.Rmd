---
title: "Constraining USGS Well Water Data"
author: "Annette Hilton"
date: "1/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Attach packages

library(tidyverse)
library(here)
library(lubridate)

# Disable scientific notation 

options(scipen=999)

```

```{r}

# Read in the full dataset for all well water measurements for the USA 

entire_usa_gw <- readr::read_tsv("entire_usgs_usa.txt")

```

```{r}
#----------------------------------------------------------------------------------------------------------
# Constrain dataset by dates 
#----------------------------------------------------------------------------------------------------------

# Remove date observations with NA values 

entire_usa_gw_dates <- entire_usa_gw %>% 
  filter(!lev_dt == "NA")

# Removed 539759 observations


```

```{r}
#--------------------------------------------------------------------------------------------------------
# Constrain by number of observations (n) 
#--------------------------------------------------------------------------------------------------------

# Constrain by number of observations (n > 1) 

# entire_usa_gw_1 <- entire_usa_gw_dates %>% 
#   group_by(site_no) %>% 
#   filter( n() > 1)
# 
# # Removed 669256 observations 

# Constrain by number of observations (n > 30) (Removed 2018880 observations)

entire_usa_gw_30 <- entire_usa_gw_dates %>%
  group_by(site_no) %>%
  filter( n() > 29)

entire_usa_gw_30_count <- entire_usa_gw_30 %>%
  count(site_no, level_year)

# Constrain by number of observations ( n > 100) (Removed 4189182 observations)

entire_usa_gw_100 <- entire_usa_gw_dates %>%
  group_by(site_no) %>%
  filter( n() > 99)

entire_usa_gw_100_count <- entire_usa_gw_100 %>%
  count(site_no, level_year)

```



```{r}
#--------------------------------------------------------------------------------------------------------
# Constrain by number of observations (n) and time-scale 
#--------------------------------------------------------------------------------------------------------

# Constrain by number of observations (n > 30) 

entire_usa_gw_30_d <- entire_usa_gw_dates %>% 
  group_by(site_no) %>% 
  filter( n() > 29) %>% 
  filter(level_year > 1940)

entire_usa_gw_30_count_d <- entire_usa_gw_30 %>% 
  count(site_no, level_year)

# Constrain by number of observations ( n > 100) 

entire_usa_gw_100_d <- entire_usa_gw_dates %>% 
  group_by(site_no) %>% 
  filter( n() > 99) 

entire_usa_gw_100_count_d <- entire_usa_gw_100 %>% 
  count(site_no, level_year)
```


**Need to brainstorm a way to sort by decadal observations**

Thoughts on data visualization 

How would I want to visualize this data? 
Changes over time. Individual sites changes over time? Entire USA changes over time with all sites (scatter)? 

### Pull latitude and longitude for ArcGIS purposes 

```{r}
#---------------------------------------------------------------------------------------------------------
# Latitude and Longitude data
#---------------------------------------------------------------------------------------------------------

# Separate latitude and longitude in separate dataframe 
# Remove duplicate site values (only keep each site once)

lat_long_entire_usa_s <- entire_usa_gw %>% 
  select(site_no, dec_lat_va, dec_long_va, state) %>% 
  distinct(site_no, .keep_all = TRUE)

lat_long_entire_usa_s$site_no <- as.numeric(lat_long_entire_usa_s$site_no)


# Write resulting dataframe to tsv 

# write_tsv(lat_long_entire_usa_s, here::here("lat_long_data", "lat_long_entire_usa_s.txt"))

# Same as above but without the state name column 

lat_long_entire_usa <- entire_usa_gw %>% 
  select(site_no, dec_lat_va, dec_long_va) %>% 
  distinct(site_no, .keep_all = TRUE) 

# Write resulting dataframe to tsv 

# write_tsv(lat_long_entire_usa, here::here("lat_long_data", "lat_long_entire_usa.txt"))

```

### Glacial Well Exercise 
```{r}
#---------------------------------------------------------------------------------------------------------
# ArcGIS Data Prep for Glacial-Well location exercise 
#---------------------------------------------------------------------------------------------------------

# Separate latitude and longitude in separate dataframe 
# Remove duplicate site values (only keep each site once)

arc_entire_usa <- entire_usa_gw %>% 
  distinct(site_no, .keep_all = TRUE) 

# Write resulting dataframe to tsv 

# write_tsv(lat_long_entire_usa, here::here("lat_long_data", "lat_long_entire_usa.txt"))

arc_entire_usa_parsed <- arc_entire_usa %>% 
  filter(!lev_dt == "NA") 

arc_entire_usa_GIS <- arc_entire_usa_parsed %>% 
  select(site_no, dec_lat_va, dec_long_va) 

# Write to tsv for import to ArcGIS 

write_tsv(arc_entire_usa_GIS, here::here("lat_long_data", "arc_entire_usa_glacial.txt"))
```

### Constrain for VHG All-USA (07/14/20) 

1. Remove values that do not have a date associated 
2. Remove values that do not have a level value associated 
3. Unique wells only 

```{r}
#----------------------------------------------------------------------------------------------------------
# Constrain dataset by dates 
#----------------------------------------------------------------------------------------------------------

# Remove date observations with NA values 
# Remove level value observations with NA values 

entire_usa_gw_unique <- entire_usa_gw %>% 
  filter(!lev_dt == "NA") %>% 
  filter(!lev_va == "NA") %>% 
  distinct(site_no, .keep_all = TRUE) %>% 
  select(site_no, dec_lat_va, dec_long_va) %>% 
  rename(lat = dec_lat_va, 
         long = dec_long_va) 

# Add character for ArcGIS workaround 

entire_usa_gw_unique$site_no <- sub("^", "x", entire_usa_gw_unique$site_no)

# Write to tsv for import to ArcGIS 

write_tsv(entire_usa_gw_unique, here::here("lat_long_data", "entire_usa_gw_unique.txt"))

```

Contiguous US only 

```{r}
#----------------------------------------------------------------------------------------------------------
# Constrain dataset by dates 
#----------------------------------------------------------------------------------------------------------

# Remove date observations with NA values 
# Remove level value observations with NA values 

entire_usa_gw_unique <- entire_usa_gw %>% 
  filter(!lev_dt == "NA") %>% 
  filter(!lev_va == "NA") %>% 
  filter(!state %in% c("alaska", "puertorico", "hawaii", "virginislands"))
  distinct(site_no, .keep_all = TRUE) %>% 
  select(site_no, dec_lat_va, dec_long_va) %>% 
  rename(lat = dec_lat_va, 
         long = dec_long_va) 

# Add character for ArcGIS workaround 

entire_usa_gw_unique$site_no <- sub("^", "x", entire_usa_gw_unique$site_no)

# Write to tsv for import to ArcGIS 

write_tsv(entire_usa_gw_unique, here::here("lat_long_data", "entire_usa_gw_unique.txt"))

```
