---
title: "USGS Data Import and Wrangling"
author: "Annette Hilton"
date: "11/6/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, error = FALSE, warning = FALSE)
```
## Introduction

This document is complimentary to "USA Well Water Data." Please reference "USA Well Water Data" for more information regarding the goals and parameters of the project.
Here I attempt to import and wrangle data for all 53 states/territories. 

## Goals and Steps 

1. Figure out how to write forloop and have the results (dataframes) for each state 
2. Figure out how to write these files to a csv and text file in the loop
3. Write a separate function to change dates to decimal dates, deal with incomplete dates, and parse out months/years 
4. Write a separate function to merge all 53 state/territory files 

## Errors and areas to fix/improve 

- Dates and decimal dates, how to deal with impartial dates? Must return to this question. Consider: 
  - Making new column that contains the length of the string 
  - Look at dates or parse dates from "left of" or "mid of" 
  -May be able to deal with incomplete dates a different way: designated date status in loop, incomplete dates are returned with 1st of month and/or 1st of year (Jan 1st), looking into how to change this default for our decimal date purposes (to mid-year) 
  -**In terms of the dates, return to the loop. Working on it but there were some errors**

 

```{r}
# Attach packages

library(tidyverse)
library(here)
library(lubridate)

# Disable scientific notation 

options(scipen=999)

```

### For-loop on USA territory files 

Here I wrote a for-loop to perform the following: 

1. Read in raw text data files (two raw data files for each state) 
  a. Specifically assign columns as they are read in with the correct format (character, numeric, etc.) to avoid parsing failures/NAs 
  b. Attempt to assign dates 
2. Merge the two files for each state 
  a. Merge by site number
  b. Full merge so nothing is ommitted, even if there is not a match between the two data files 
  c. Remove columns that are not of interest, tidy the dataframe 
3. Pull the state name for each dataframe produced and return each state individually
4. Write each individual final state dataframe to a text file and csv file

**NOTES**

- There was an issue with the loop reading in the "Arkansas" files for "Kansas," presumably because the spelling is nearly identical. I switched the file names of Kansas in order rectify this, which works--however I will look for a better solution so Kansas does not have to be permanently named "Kansassecond." 
  

```{r}
#------------------------------------------------------------------------------------
# Here I set up the information necessary for the for-loop
#------------------------------------------------------------------------------------

# Tell R where to find the files 
files <- list.files(path = (here::here("raw_data")))

# Create a vector with all of the state names 
state <- c("alabama", "alaska", "arizona", "arkansas", "california", "colorado", "connecticut", "delaware", "districtcolumbia", "florida", "georgia", "hawaii", "idaho", "illinois", "indiana", "iowa", "kansassecond", "kentucky", "louisiana", "maine", "maryland", "massachusetts", "michigan", "minnesota", "mississippi", "missouri", "montana", "nebraska", "nevada", "newhampshire", "newjersey", "newmexico", "newyork", "northcarolina", "northdakota", "ohio", "oklahoma", "oregon", "pennsylvania", "puertorico", "rhodeisland", "southcarolina", "southdakota", "tennessee", "texas", "utah", "vermont", "virginia", "virginislands", "washington", "westvirginia", "wisconsin", "wyoming")
```



```{r}
#---------------------------------------------------------------------------------
# This is the for loop with the objectives described above
#---------------------------------------------------------------------------------

# Specify output/result of the loop (a dataframe that pulls the individual state names)

results <- data.frame(files = "state")

# For-loop 

for (i in 1:length(state)) { # Identifying to pull state names 
  name = state[i]
  df_name = paste0("df_", name)
  
# The file path and indicator to pull files based on the pattern (state name)  
  
  state_files = list.files(path = (here::here("raw_data")), 
                                   pattern = name)  
  
# Each file is identified based on the order of files (there are two different USGS files) 
  
  raw_import <- state_files[1] 
  import <- state_files[2]

# Read in first file type 
# Specify column types 
  
  raw_import_usgs <- read_tsv(here::here("raw_data", raw_import),
                              col_types = cols(
                                agency_cd = col_character(),
                                site_no = col_double(),
                                site_tp_cd = col_character(),
                                lev_dt = col_character(),
                                lev_tm = col_character(),
                                lev_tz_cd = col_character(), 
                                lev_va = col_double(), 
                                sl_lev_va = col_character(), 
                                sl_datum_cd = col_character(), 
                                lev_status_cd = col_character(),
                                lev_agency_cd = col_character(),
                                lev_dt_acy_cd = col_character(),
                                lev_acy_cd = col_character(), 
                                lev_src_cd = col_character(),
                                lev_meth_cd = col_character()
                                  
                                   )) 
  
  
# Read in second file type 
# Specify column types 
  
  import_usgs <- read_tsv(here::here("raw_data", import),
                          col_types = cols(
                            agency_cd = col_character(),
                            site_no = col_double(),
                            station_nm = col_character(),
                            dec_lat_va = col_double(),
                            dec_long_va = col_double(),
                            coord_acy_cd = col_character(), 
                            dec_coord_datum_cd = col_character(),
                            alt_va = col_double(),
                            alt_acy_va = col_double(),
                            alt_datum_cd = col_character(),
                            well_depth_va = col_double(),
                            hole_depth_va = col_double()
                          ))

# Merge both files using full_join() and merge by column "site_no" 
# Use mutate to add a column for state name and add column for level_date that R recognizes as a date
  
  state_files_merge <- full_join(x = import_usgs, y = raw_import_usgs, by = "site_no", copy = FALSE) %>% 
    mutate(state = name)
      # level_date = lubridate::parse_date_time(lev_dt, orders = c("ymd", "Y!", "Ym"), train = FALSE), 
      # level_decimal_date = lubridate::decimal_date(level_date),
      # level_month = lubridate::month(level_date, label = TRUE),
      # level_year = lubridate::year(level_date))
  
# Tidy data and remove excess columns in new dataframe 
  
  state_files_usgs <- state_files_merge %>% 
    select(-station_nm, -coord_acy_cd, -agency_cd.x, -lev_tm, -sl_lev_va : -lev_age_cd) 

# Call the results specified above for the for-loop (the final merged dataframe) 
# Assign each state name to its corresponding final merged dataframe 
  
  results <- state_files_usgs

  assign(df_name, results)
  
# Write the resulting dataframes of all 53 state/territories to csv files and tsv files, saved in separate folders 
  
  # write_csv(results, here::here("merged_state_data_csv", file = paste0(df_name, ".csv")))
  # write_tsv(results, here::here("merged_state_data_tsv", file = paste0(df_name, ".txt")))
  }


```


### Merge all dataframes to final dataframe 

```{r}

# Create list of dataframes for rbind function (all 53 states/territories)

merge_list <- mget(ls(pattern = "df_"))

# Use the do.call function and rbind to merge all of the dataframes from the list vertically (since variables are the same) 

entire_usgs_usa <- do.call("rbind", merge_list)


```

### Pull latitude and longitude for ArcGIS purposes 

Something is going wrong here. First of all, just to be aware, the entire_usgs_usa is all characters (ugh) 

```{r}

# Separate latitude and longitude in separate dataframe 
# Remove duplicate site values (only keep each site once)

lat_long_entire_usa_s <- entire_usgs_usa %>% 
  select(site_no, dec_lat_va, dec_long_va, state) %>% 
  distinct(site_no, .keep_all = TRUE)


# Write resulting dataframe to tsv 

write_tsv(lat_long_entire_usa_s, here::here("lat_long_data", "lat_long_entire_usa_s.txt"))

# Same as above but without the state name column 

lat_long_entire_usa <- entire_usgs_usa %>% 
  select(site_no, dec_lat_va, dec_long_va) %>% 
  distinct(site_no, .keep_all = TRUE) 

# Write resulting dataframe to tsv 

write_tsv(lat_long_entire_usa, here::here("lat_long_data", "lat_long_entire_usa.txt"))

  
  
```

